# Chess Reasoning SFT Training Configuration

model:
  name: "amazingvince/chess_qwen3_4b_reasoning"
  torch_dtype: "bfloat16"
  attn_implementation: "flash_attention_2"

dataset:
  name: "amazingvince/chess-traces"
  eval_holdout_size: 500
  max_length: 8192

training:
  per_device_train_batch_size: 64
  per_device_eval_batch_size: 32
  gradient_accumulation_steps: 1
  learning_rate: 2.0e-5
  lr_scheduler_type: "cosine"
  warmup_ratio: 0.0001
  num_train_epochs: 1
  max_steps: 10000
  optim: "adamw_torch_fused"
  max_grad_norm: 1.0
  weight_decay: 0.01
  bf16: true
  tf32: true

optimization:
  gradient_checkpointing: true
  use_liger_kernel: true
  padding_free: true

# Chess-specific evaluation (runs via callback)
evaluation:
  eval_steps: 1000
  batch_size: 16          # Batch size for generation during eval
  max_new_tokens: 2048    # Max tokens to generate (thinking + move)
  stockfish:
    depth: 15
    eval_samples: 32

saving:
  save_strategy: "steps"
  save_steps: 1000
  save_total_limit: 1
  output_dir: "./chess_qwen3_4b_reasoning"

hub:
  push_to_hub: true
  hub_model_id: "amazingvince/chess_qwen3_4b_reasoning_v2"
  hub_strategy: "checkpoint"
  hub_private_repo: true

wandb:
  project: "chess-reasoning-sft"
  run_name: "chess-qwen3-4b-reasoning"

logging:
  logging_steps: 10
  logging_first_step: true
